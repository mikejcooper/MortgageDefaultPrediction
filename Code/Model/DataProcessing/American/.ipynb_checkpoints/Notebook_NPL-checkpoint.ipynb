{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Performing Loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract NPL from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e928566d329c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df_np.to_csv(\"npl_loans_subset\", sep='|')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbackup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"npl_loans_subset.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbackup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbackup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunk_size' is not defined"
     ]
    }
   ],
   "source": [
    "# df_np.to_csv(\"npl_loans_subset\", sep='|')\n",
    "backup = pd.HDFStore(\"npl_loans_subset.h5\")\n",
    "backup['df'] = pd.DataFrame([chunk_size])\n",
    "backup.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_np.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOAN_COUNT = len(np.unique(df_np['id_loan'].values))\n",
    "FICO_MEAN = df_np['fico'].mean()\n",
    "BALANCE_MEAN = df_np['orig_upb'].mean()\n",
    "FICO_MEDIAN = df_np['fico'].median()\n",
    "FICO_MEDIAN = df_np['fico'].median()\n",
    "LOAN_LENGTH_MEAN = df_np.groupby(['id_loan']).size().mean()\n",
    "DEFAULT_LOANS_COUNT = len(df_np.loc[df_np['label_good_bad_loan'] == 0]['id_loan'].unique())\n",
    "FULLY_PAID_LOANS_COUNT = len(df_np.loc[df_np['label_good_bad_loan'] == 1]['id_loan'].unique())\n",
    "\n",
    "print \"FICO_MEDIAN: \" + str(int(FICO_MEDIAN))\n",
    "print \"FICO_MEAN: \" + str(int(FICO_MEAN))\n",
    "print \"LOAN_COUNT: \" + str(int(LOAN_COUNT))\n",
    "print \"ORIGINAL_BALANCE_MEAN: $\" + str(int(BALANCE_MEAN))\n",
    "print \"LOAN_LENGTH_MEAN (months): \" + str(int(LOAN_LENGTH_MEAN))\n",
    "print \"Number of Default Loans :\" + str(int(DEFAULT_LOANS_COUNT))\n",
    "print \"Number of Fully Paid Loans :\" + str(int(FULLY_PAID_LOANS_COUNT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_dataframe_to_st(df_IN):\n",
    "    df_st_names = DataParser().st_names()\n",
    "    df_filled = pd.merge(df_st_names, df_IN, on='st', how='outer')\n",
    "    for col in df_filled.columns.values:\n",
    "        df_filled[col] = df_filled[col].fillna(0)\n",
    "    return df_filled\n",
    "\n",
    "#  Calculate number of npls per state \n",
    "df_st_count = df_np.drop_duplicates(subset=['id_loan']).groupby(['st']).size().to_frame()\n",
    "df_st_count.reset_index(level=0, inplace=True)\n",
    "df_st_count.columns = ['st', 'st_loan_count']\n",
    "df_np = pd.merge(df_np, df_st_count, on='st', how='left')\n",
    "df_np['st_loan_count']= df_np['st_loan_count'].fillna(0)\n",
    "\n",
    "df_st = df_np.sort_values(['st_loan_count'], ascending=[False])\n",
    "df_st = df_st.drop_duplicates(subset=['st'], keep='first')\n",
    "df_st = df_st.loc[df_st['st'] != 'PR']\n",
    "df_st = fill_dataframe_to_st(df_st)\n",
    "df_st = df_st.sort_values(['st_loan_count'], ascending=[True])\n",
    "\n",
    "st_col = df_st['st'].values\n",
    "occr_loans_per_state_col = df_st['st_loan_count'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_st[['st', 'st_name', 'st_loan_count', 'rt_default_per_state']]\n",
    "df = df.rename(columns={'st': 'code'})\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n",
    "            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n",
    "\n",
    "df['text'] = df['st_name'] + '<br>' + 'Default Rate : ' + df['rt_default_per_state'].astype(float).round(4).astype(str)\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = df['code'],\n",
    "        z = df['st_loan_count'].astype(float),\n",
    "        locationmode = 'USA-states',\n",
    "        text = df['text'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"#\")\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Number of Loans by State<br>(Hover for breakdown)',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, filename='d3-cloropleth-map' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace1 = go.Bar(\n",
    "    x=df_st['st_loan_count'].values,\n",
    "    y=df_st['st'].values,\n",
    "    name='st_loan_count',\n",
    "    orientation = 'h',\n",
    ")\n",
    "data = [trace1]\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=500,\n",
    "    height=1000,\n",
    "    barmode='stack'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='horizontal-stacked-bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
